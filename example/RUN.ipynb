{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Regularized Unfolding\n",
    "\n",
    "RUN reconstructs fits the target distribution `f` to the convolution model `g = R * f`, using maximum likelihood. The regularization strength is configured with `n_df`, the effective number of degrees of freedom in the second-order local model of the solution.\n",
    "\n",
    "For a quick start, we deconvolve the distribution of Iris plant types in the famous IRIS data set."
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# load the example data\n",
    "using MLDataUtils\n",
    "X, y_labels, _ = load_iris()\n",
    "\n",
    "# discretize the target quantity (for numerical values, we'd use LinearDiscretizer)\n",
    "using Discretizers: encode, CategoricalDiscretizer\n",
    "y = encode(CategoricalDiscretizer(y_labels), y_labels) # vector of target value indices\n",
    ";"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "collapsed": true
   },
   "outputs": [],
   "source": [
    "# Split the data into training and observed data sets.\n",
    "# \n",
    "# The matrices MLDataUtils expects are transposed, by default.\n",
    "# Thus, we have to be explicit about obsdim = 1. Note that\n",
    "# CherenkovDeconvolution.jl follows the convention of ScikitLearn.jl\n",
    "# (and others), which is size(X_train) == (n_examples, n_features).\n",
    "# \n",
    "# MLDataUtils unfortunately assumes size(X_train) == (n_features, n_examples),\n",
    "# but obsdim = 1 fixes this assumption.\n",
    "# \n",
    "srand(42) # make split reproducible\n",
    "(X_train, y_train), (X_data, y_data) = splitobs(shuffleobs((X', y), obsdim = 1), obsdim = 1);"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[36mINFO: \u001b[39m\u001b[22m\u001b[36mUtilities of ScikitLearn.jl are available in CherenkovDeconvolution.Sklearn\n",
      "\u001b[39m"
     ]
    },
    {
     "data": {
      "text/plain": [
       "6-element Array{Int64,1}:\n",
       " 1\n",
       " 2\n",
       " 3\n",
       " 4\n",
       " 5\n",
       " 6"
      ]
     },
     "execution_count": 3,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# RUN is only applicable with a single discrete observable dimension. In order to obtain \n",
    "# a dimension that contains as much information as possible, we discretize the feature\n",
    "# space with a decision tree, using its leaves as clusters. The cluster indices are the\n",
    "# discrete values of the observed dimension. This concepts relates to supervised clustering.\n",
    "#\n",
    "using ScikitLearn, CherenkovDeconvolution.Sklearn\n",
    "\n",
    "td = TreeDiscretizer(X_train, y_train, 6) # obtain (up to) 6 clusters\n",
    "x_train = encode(td, X_train)\n",
    "x_data  = encode(td, X_data)\n",
    "\n",
    "# have a look at the content of x_train\n",
    "unique(x_train) # its the cluster indices"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "\u001b[1m\u001b[33mWARNING: \u001b[39m\u001b[22m\u001b[33mLimiting RUN to 3 of 6 observeable non-zero bins\u001b[39m\n"
     ]
    },
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.333333\n",
       " 0.356313\n",
       " 0.35    "
      ]
     },
     "execution_count": 4,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Now let's estimate the target distribution!\n",
    "#\n",
    "using CherenkovDeconvolution\n",
    "\n",
    "f_est = CherenkovDeconvolution.run(x_data, x_train, y_train) # returns a vector of target value probabilities"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "3-element Array{Float64,1}:\n",
       " 0.333333\n",
       " 0.355556\n",
       " 0.311111"
      ]
     },
     "execution_count": 5,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#\n",
    "# Compare the result to the true target distribution, which we are estimating\n",
    "#\n",
    "f_true = Util.fit_pdf(y_data) # f_est is almost equal to f_true!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {
    "collapsed": false
   },
   "outputs": [
    {
     "data": {
      "text/markdown": [
       "```\n",
       "run(data, train, y, x; kwargs...)\n",
       "```\n",
       "\n",
       "Regularized Unfolding of the target distribution in the DataFrame `data`. The deconvolution is inferred from the DataFrame `train`, where the target column `y` and the observable column `x` are given.\n",
       "\n",
       "This function wraps `run(R, g; kwargs...)`, constructing `R` and `g` from the examples in the two DataFrames.\n",
       "\n",
       "```\n",
       "run(x_data, x_train, y_train; kwargs...)\n",
       "```\n",
       "\n",
       "Regularized Unfolding of the target distribution, given the observations in the one-dimensional array `x_data`. The deconvolution is inferred from `x_train` and `y_train`.\n",
       "\n",
       "This function wraps `run(R, g; kwargs...)`, constructing `R` and `g` from the examples in the three arrays.\n",
       "\n",
       "```\n",
       "run(R, g, n_df = size(R, 2); kwargs...)\n",
       "```\n",
       "\n",
       "Perform RUN with the observed pdf `g`, the detector response matrix `R`, and `n_df` degrees of freedom. The default `n_df` results in no regularization (there is one degree of freedom for each dimension in the result).\n",
       "\n",
       "**Keyword arguments**\n",
       "\n",
       "  * `K = 100` is the maximum number of iterations.\n",
       "  * `epsilon = 1e-6` is the minimum difference in the loss function between iterations. RUN stops when the absolute loss difference drops below `epsilon`.\n",
       "  * `inspect = nothing` is a function `(k::Int, tau::Float64, ldiff::Float64, f_k::Array) -> Any` optionally called in every iteration.\n",
       "  * `loggingstream = DevNull` is an optional `IO` stream to write log messages to.\n"
      ],
      "text/plain": [
       "```\n",
       "run(data, train, y, x; kwargs...)\n",
       "```\n",
       "\n",
       "Regularized Unfolding of the target distribution in the DataFrame `data`. The deconvolution is inferred from the DataFrame `train`, where the target column `y` and the observable column `x` are given.\n",
       "\n",
       "This function wraps `run(R, g; kwargs...)`, constructing `R` and `g` from the examples in the two DataFrames.\n",
       "\n",
       "```\n",
       "run(x_data, x_train, y_train; kwargs...)\n",
       "```\n",
       "\n",
       "Regularized Unfolding of the target distribution, given the observations in the one-dimensional array `x_data`. The deconvolution is inferred from `x_train` and `y_train`.\n",
       "\n",
       "This function wraps `run(R, g; kwargs...)`, constructing `R` and `g` from the examples in the three arrays.\n",
       "\n",
       "```\n",
       "run(R, g, n_df = size(R, 2); kwargs...)\n",
       "```\n",
       "\n",
       "Perform RUN with the observed pdf `g`, the detector response matrix `R`, and `n_df` degrees of freedom. The default `n_df` results in no regularization (there is one degree of freedom for each dimension in the result).\n",
       "\n",
       "**Keyword arguments**\n",
       "\n",
       "  * `K = 100` is the maximum number of iterations.\n",
       "  * `epsilon = 1e-6` is the minimum difference in the loss function between iterations. RUN stops when the absolute loss difference drops below `epsilon`.\n",
       "  * `inspect = nothing` is a function `(k::Int, tau::Float64, ldiff::Float64, f_k::Array) -> Any` optionally called in every iteration.\n",
       "  * `loggingstream = DevNull` is an optional `IO` stream to write log messages to.\n"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "?CherenkovDeconvolution.run # You can find more information in the documentation"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Julia 0.6.2",
   "language": "julia",
   "name": "julia-0.6"
  },
  "language_info": {
   "file_extension": ".jl",
   "mimetype": "application/julia",
   "name": "julia",
   "version": "0.6.2"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
